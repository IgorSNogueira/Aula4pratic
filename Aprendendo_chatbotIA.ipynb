{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOlypSTccX4BXykY3DNb2Sq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/IgorSNogueira/Aula4pratic/blob/main/Aprendendo_chatbotIA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Instalando o SDK"
      ],
      "metadata": {
        "id": "J3HAuVgWzY9C"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "CUsl7P1gxGjg"
      },
      "outputs": [],
      "source": [
        "# Intalando a dependências\n",
        "!pip install -q -U google-generativeai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Importando a biblioteca\n",
        "import google.generativeai as genai\n",
        "\n",
        "# Aplicando e configurando a chave\n",
        "GOOGLE_API_KEY= 'INSIRA SUA API KAY AQUI!'\n",
        "genai.configure(api_key=GOOGLE_API_KEY)"
      ],
      "metadata": {
        "id": "1eW6j9sKxese"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Listando os modelos"
      ],
      "metadata": {
        "id": "hHU_F2jszm91"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for m in genai.list_models():\n",
        "  if 'generateContent' in m.supported_generation_methods:\n",
        "    print(m.name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "id": "-Z_zjQVGyED2",
        "outputId": "9c9a923d-cd16-4886-f59e-3d72a10821dc"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "models/gemini-1.0-pro\n",
            "models/gemini-1.0-pro-001\n",
            "models/gemini-1.0-pro-latest\n",
            "models/gemini-1.0-pro-vision-latest\n",
            "models/gemini-1.5-pro-latest\n",
            "models/gemini-pro\n",
            "models/gemini-pro-vision\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "configuracao_generativa = {\n",
        "    \"candidate_count\": 1,\n",
        "    \"temperature\": 0.7,\n",
        "}"
      ],
      "metadata": {
        "id": "Tzh5vWQG3vMZ"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "configuracao_seguranca = {\n",
        "    \"HARASSMENT\": \"BLOCK_NONE\",\n",
        "    \"HATE\": \"BLOCK_NONE\",\n",
        "    \"SEXUAL\": \"BLOCK_NONE\",\n",
        "    \"DANGEROUS\": \"BLOCK_NONE\"\n",
        "}"
      ],
      "metadata": {
        "id": "FTyICpCr4fyB"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Inicializando o modelo"
      ],
      "metadata": {
        "id": "wPhfoOvK57_v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = genai.GenerativeModel(model_name = \"gemini-1.0-pro\", generation_config = configuracao_generativa, safety_settings = configuracao_seguranca)"
      ],
      "metadata": {
        "id": "bQHBma7P5lqW"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "O response vai gerar a resposta via o model.generate_content baseado na entrada que está entre parenteses, e o print do response.text imprimirá a resposta textual. embora possa der usado vários métodos para transformar isso em um loop, existe outro método mais eficiente."
      ],
      "metadata": {
        "id": "mwDy1d6F8Wln"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#response = model.generate_content(\"Qual a previsão do tempo ?\")\n",
        "#print(response.text)"
      ],
      "metadata": {
        "id": "OXANlRaK8U0Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Criando Chatbot com o input para interação."
      ],
      "metadata": {
        "id": "aoJ3HDoH_aut"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chat = model.start_chat(history =[])"
      ],
      "metadata": {
        "id": "C3rWPn3j_fqK"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"Resetando o valor para replay\" # redundância ;)\n",
        "\n",
        "while True:\n",
        "  print('Digite seu comando abaixo, ou digite finalizar para encerrar!')\n",
        "  prompt = input('Digite aqui: ')\n",
        "  if prompt == 'finalizar':\n",
        "    print('\\nObrigado e volte sempre\\n----Programa Finalizado----')\n",
        "    break\n",
        "  else:\n",
        "    print(f'\\nPensando...\\n')\n",
        "    response = chat.send_message(prompt)\n",
        "    print(f'---Resposta---\\n{response.text}\\nPosso ajudar em algo mais ?')"
      ],
      "metadata": {
        "id": "axVV8OJ8Bega"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}